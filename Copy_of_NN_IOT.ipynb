{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NN_IOT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VineetMakharia/NN-ipynbs/blob/main/Copy_of_NN_IOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCq1ygRWOo5T",
        "outputId": "cb1bff5e-a9a0-4bc0-ec51-e47913409463",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        " from google.colab import files \n",
        "  \n",
        "  \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45dc426d-c1d7-41f8-b96b-2fe5700c7ac1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45dc426d-c1d7-41f8-b96b-2fe5700c7ac1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 9.csv to 9.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq81MtCWOyes"
      },
      "source": [
        "import pandas as pd \n",
        "import io \n",
        "  \n",
        "df = pd.read_csv(io.BytesIO(uploaded['9.csv']), names= ['x1', 'x2', 'x3', 'x4', 'x5', 'y']) "
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTN1sXzJS0RT",
        "outputId": "fb5e43d1-ff92-4d27-9327-e4e2fee92d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "X = df[['x1','x2','x3','x4','x5']]\n",
        "X.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43.060</td>\n",
              "      <td>80.829</td>\n",
              "      <td>154.37</td>\n",
              "      <td>205.63</td>\n",
              "      <td>253.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54.100</td>\n",
              "      <td>79.580</td>\n",
              "      <td>118.67</td>\n",
              "      <td>207.98</td>\n",
              "      <td>257.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49.086</td>\n",
              "      <td>76.696</td>\n",
              "      <td>136.36</td>\n",
              "      <td>212.10</td>\n",
              "      <td>243.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.767</td>\n",
              "      <td>91.612</td>\n",
              "      <td>122.82</td>\n",
              "      <td>236.30</td>\n",
              "      <td>245.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.154</td>\n",
              "      <td>85.700</td>\n",
              "      <td>116.98</td>\n",
              "      <td>245.92</td>\n",
              "      <td>262.81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       x1      x2      x3      x4      x5\n",
              "0  43.060  80.829  154.37  205.63  253.82\n",
              "1  54.100  79.580  118.67  207.98  257.62\n",
              "2  49.086  76.696  136.36  212.10  243.83\n",
              "3  35.767  91.612  122.82  236.30  245.87\n",
              "4  55.154  85.700  116.98  245.92  262.81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQVnxBXS6RX",
        "outputId": "1bdb1ea9-8173-47ac-c249-7cbff5142aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "Y = df[['y']]\n",
        "Y.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5659.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5517.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5514.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5662.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5864.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        y\n",
              "0  5659.4\n",
              "1  5517.6\n",
              "2  5514.7\n",
              "3  5662.9\n",
              "4  5864.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-STvxeHunc_1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Total 2300 samples, need 300 for test, so testsize = 300/2300 ~= 0.13\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.13)\n",
        "assert len(X_train) + len(X_test) == len(X)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u_LVYEnbQGg"
      },
      "source": [
        "# Need to use a scaler for a neural network, popular ones are Standard Scaler and Min Max Scaler\n",
        "# It is important to scale our train and test separately else we might get skewed results.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFQsgekuiXG",
        "outputId": "edcefd2e-0f11-4d6c-b6e3-2f2804697eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2001, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqVgg8Ix5wYP"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXcaVqFG6n4a"
      },
      "source": [
        "### Creating a base model with some parameters to find the R2 value, we are looking to get closer to a value of 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pB-DIGrP193"
      },
      "source": [
        "def base_model(optimizer='adam',unit = 256,kernel_initializer='normal'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, kernel_initializer='normal',input_dim = 5, activation='relu'))\n",
        "\n",
        "  # Creating 3 hidden layers\n",
        "  model.add(Dense(units=unit, kernel_initializer=kernel_initializer,activation='relu'))\n",
        "  model.add(Dense(units=unit, kernel_initializer=kernel_initializer,activation='relu'))\n",
        "  model.add(Dense(units=unit, kernel_initializer=kernel_initializer,activation='relu'))\n",
        "\n",
        "  # The Output Layer :\n",
        "  model.add(Dense(1, kernel_initializer=kernel_initializer,activation='linear'))\n",
        "\n",
        "  model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYjt86bteI13",
        "outputId": "3f84602d-ce6a-4204-95c4-cbc7cf38ad42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = base_model()\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=256,\n",
        "          epochs=500)\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_85 (Dense)             (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 165,633\n",
            "Trainable params: 165,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 5566.8324 - mean_absolute_error: 5566.8325\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 5564.3927 - mean_absolute_error: 5564.3928\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 5550.1851 - mean_absolute_error: 5550.1852\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5491.3732 - mean_absolute_error: 5491.3733\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 5300.9035 - mean_absolute_error: 5300.9035\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 4775.0021 - mean_absolute_error: 4775.0021\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 3493.6850 - mean_absolute_error: 3493.6850\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1481.0210 - mean_absolute_error: 1481.0210\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1387.9600 - mean_absolute_error: 1387.9601\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 986.4605 - mean_absolute_error: 986.4605\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 927.0869 - mean_absolute_error: 927.0869\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 875.2221 - mean_absolute_error: 875.2221\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 815.0141 - mean_absolute_error: 815.0141\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 771.8243 - mean_absolute_error: 771.8243\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 729.4012 - mean_absolute_error: 729.4012\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 687.5706 - mean_absolute_error: 687.5706\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 643.9877 - mean_absolute_error: 643.9876\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 599.4813 - mean_absolute_error: 599.4813\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 550.6631 - mean_absolute_error: 550.6631\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 502.6077 - mean_absolute_error: 502.6077\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 454.6241 - mean_absolute_error: 454.6241\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 400.9906 - mean_absolute_error: 400.9906\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 345.5469 - mean_absolute_error: 345.5469\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 291.9551 - mean_absolute_error: 291.9551\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 240.7386 - mean_absolute_error: 240.7386\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 192.8077 - mean_absolute_error: 192.8077\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 150.7907 - mean_absolute_error: 150.7907\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 115.6916 - mean_absolute_error: 115.6916\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 89.5222 - mean_absolute_error: 89.5222\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 68.5396 - mean_absolute_error: 68.5396\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 53.9696 - mean_absolute_error: 53.9696\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 42.0240 - mean_absolute_error: 42.0240\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 51.6380 - mean_absolute_error: 51.6380\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 55.4890 - mean_absolute_error: 55.4890\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 53.4062 - mean_absolute_error: 53.4062\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 69.7289 - mean_absolute_error: 69.7289\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 64.2942 - mean_absolute_error: 64.2942\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 47.4176 - mean_absolute_error: 47.4176\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 46.1272 - mean_absolute_error: 46.1272\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 32.2105 - mean_absolute_error: 32.2105\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.4485 - mean_absolute_error: 20.4485\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 25.0222 - mean_absolute_error: 25.0222\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 23.1706 - mean_absolute_error: 23.1706\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 25.3487 - mean_absolute_error: 25.3487\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 35.6102 - mean_absolute_error: 35.6102\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 34.3292 - mean_absolute_error: 34.3292\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 29.4133 - mean_absolute_error: 29.4133\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 33.0619 - mean_absolute_error: 33.0619\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 30.5153 - mean_absolute_error: 30.5153\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 29.4273 - mean_absolute_error: 29.4273\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 36.2468 - mean_absolute_error: 36.2468\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 37.7983 - mean_absolute_error: 37.7983\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.4658 - mean_absolute_error: 18.4658\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.8311 - mean_absolute_error: 14.8311\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16.5733 - mean_absolute_error: 16.5733\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 17.3594 - mean_absolute_error: 17.3594\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.8153 - mean_absolute_error: 15.8153\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 30.3525 - mean_absolute_error: 30.3525\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 34.3732 - mean_absolute_error: 34.3732\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.3274 - mean_absolute_error: 27.3274\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 27.5027 - mean_absolute_error: 27.5027\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 28.7208 - mean_absolute_error: 28.7208\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 25.9662 - mean_absolute_error: 25.9662\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 28.9596 - mean_absolute_error: 28.9596\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 23.2606 - mean_absolute_error: 23.2606\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.7381 - mean_absolute_error: 17.7381\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 29.3207 - mean_absolute_error: 29.3207\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 35.2644 - mean_absolute_error: 35.2644\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 24.7768 - mean_absolute_error: 24.7768\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.5116 - mean_absolute_error: 24.5116\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 22.3897 - mean_absolute_error: 22.3897\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 32.4528 - mean_absolute_error: 32.4528\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 33.1411 - mean_absolute_error: 33.1412\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 30.7393 - mean_absolute_error: 30.7393\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 28.2970 - mean_absolute_error: 28.2970\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 28.1335 - mean_absolute_error: 28.1335\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 31.6400 - mean_absolute_error: 31.6400\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 30.0967 - mean_absolute_error: 30.0967\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 30.4368 - mean_absolute_error: 30.4368\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 34.0909 - mean_absolute_error: 34.0909\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 18.8020 - mean_absolute_error: 18.8020\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 15.6740 - mean_absolute_error: 15.6740\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 14.0238 - mean_absolute_error: 14.0238\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.0877 - mean_absolute_error: 15.0877\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.3014 - mean_absolute_error: 16.3014\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.3940 - mean_absolute_error: 10.3940\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.1169 - mean_absolute_error: 22.1169\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 21.6727 - mean_absolute_error: 21.6727\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.4377 - mean_absolute_error: 18.4377\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.4479 - mean_absolute_error: 24.4479\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 22.4827 - mean_absolute_error: 22.4827\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.0996 - mean_absolute_error: 20.0996\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.0094 - mean_absolute_error: 23.0094\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14.4283 - mean_absolute_error: 14.4283\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.0597 - mean_absolute_error: 12.0597\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.5891 - mean_absolute_error: 9.5891\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.6358 - mean_absolute_error: 10.6358\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.9855 - mean_absolute_error: 12.9855\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.3070 - mean_absolute_error: 12.3070\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.0730 - mean_absolute_error: 23.0730\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 23.4187 - mean_absolute_error: 23.4187\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 24.1056 - mean_absolute_error: 24.1056\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 20.5890 - mean_absolute_error: 20.5890\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.4293 - mean_absolute_error: 21.4293\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.6904 - mean_absolute_error: 17.6904\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.4572 - mean_absolute_error: 12.4572\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.1433 - mean_absolute_error: 14.1433\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 26.9625 - mean_absolute_error: 26.9625\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 26.1565 - mean_absolute_error: 26.1565\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.1513 - mean_absolute_error: 15.1513\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 14.9537 - mean_absolute_error: 14.9537\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.9666 - mean_absolute_error: 18.9666\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 19.7340 - mean_absolute_error: 19.7340\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.0283 - mean_absolute_error: 16.0283\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 14.9983 - mean_absolute_error: 14.9983\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.7535 - mean_absolute_error: 22.7535\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 20.9313 - mean_absolute_error: 20.9313\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 22.5988 - mean_absolute_error: 22.5988\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 22.4304 - mean_absolute_error: 22.4304\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 28.9507 - mean_absolute_error: 28.9507\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 25.7679 - mean_absolute_error: 25.7679\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.9803 - mean_absolute_error: 20.9803\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.0155 - mean_absolute_error: 14.0155\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.5791 - mean_absolute_error: 12.5791\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.6725 - mean_absolute_error: 12.6725\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.3580 - mean_absolute_error: 17.3580\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 29.2048 - mean_absolute_error: 29.2048\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.6314 - mean_absolute_error: 24.6314\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 37.2218 - mean_absolute_error: 37.2218\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 27.5463 - mean_absolute_error: 27.5463\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.7306 - mean_absolute_error: 19.7306\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.7540 - mean_absolute_error: 21.7540\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.9937 - mean_absolute_error: 19.9937\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 27.0183 - mean_absolute_error: 27.0183\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 27.5959 - mean_absolute_error: 27.5959\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 34.8848 - mean_absolute_error: 34.8848\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 28.4970 - mean_absolute_error: 28.4970\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 32.4872 - mean_absolute_error: 32.4872\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 28.9059 - mean_absolute_error: 28.9059\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.6514 - mean_absolute_error: 23.6514\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 34.6875 - mean_absolute_error: 34.6875\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 26.6994 - mean_absolute_error: 26.6994\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.1936 - mean_absolute_error: 16.1936\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.9569 - mean_absolute_error: 19.9569\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.4951 - mean_absolute_error: 15.4951\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.2737 - mean_absolute_error: 13.2737\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.1237 - mean_absolute_error: 12.1237\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.0301 - mean_absolute_error: 17.0301\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 20.8786 - mean_absolute_error: 20.8786\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.4466 - mean_absolute_error: 18.4466\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.0433 - mean_absolute_error: 19.0433\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 26.8456 - mean_absolute_error: 26.8456\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 29.3235 - mean_absolute_error: 29.3235\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.2690 - mean_absolute_error: 20.2690\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.9609 - mean_absolute_error: 19.9609\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.0978 - mean_absolute_error: 19.0978\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 18.0449 - mean_absolute_error: 18.0449\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.7571 - mean_absolute_error: 17.7571\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 29.0778 - mean_absolute_error: 29.0778\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 21.7719 - mean_absolute_error: 21.7719\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 28.9262 - mean_absolute_error: 28.9262\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 22.0830 - mean_absolute_error: 22.0830\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.5895 - mean_absolute_error: 13.5895\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 27.0932 - mean_absolute_error: 27.0932\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 16.3399 - mean_absolute_error: 16.3399\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.3972 - mean_absolute_error: 18.3972\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 19.7451 - mean_absolute_error: 19.7451\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.6304 - mean_absolute_error: 23.6304\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 26.6388 - mean_absolute_error: 26.6388\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 22.6280 - mean_absolute_error: 22.6280\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.0774 - mean_absolute_error: 27.0774\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 19.8759 - mean_absolute_error: 19.8759\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.7591 - mean_absolute_error: 21.7591\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14.4313 - mean_absolute_error: 14.4313\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11.4443 - mean_absolute_error: 11.4443\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.0897 - mean_absolute_error: 10.0897\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.4311 - mean_absolute_error: 13.4311\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14.6962 - mean_absolute_error: 14.6962\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 22.6308 - mean_absolute_error: 22.6308\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 29.0968 - mean_absolute_error: 29.0968\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 27.2912 - mean_absolute_error: 27.2912\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16.2095 - mean_absolute_error: 16.2095\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.4938 - mean_absolute_error: 17.4938\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 18.6340 - mean_absolute_error: 18.6340\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 16.6405 - mean_absolute_error: 16.6405\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 18.3407 - mean_absolute_error: 18.3407\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.4159 - mean_absolute_error: 19.4158\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.7629 - mean_absolute_error: 12.7629\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11.0677 - mean_absolute_error: 11.0677\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.7423 - mean_absolute_error: 9.7423\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 10.7224 - mean_absolute_error: 10.7224\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.9706 - mean_absolute_error: 9.9706\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 12.0580 - mean_absolute_error: 12.0580\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 25.8031 - mean_absolute_error: 25.8031\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 24.3667 - mean_absolute_error: 24.3667\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11.0044 - mean_absolute_error: 11.0044\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 15.4997 - mean_absolute_error: 15.4997\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 15.8073 - mean_absolute_error: 15.8073\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11.3568 - mean_absolute_error: 11.3568\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.2632 - mean_absolute_error: 19.2632\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 28.4530 - mean_absolute_error: 28.4530\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 39.6810 - mean_absolute_error: 39.6810\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 40.3620 - mean_absolute_error: 40.3620\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 34.5807 - mean_absolute_error: 34.5807\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 33.1521 - mean_absolute_error: 33.1521\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.4708 - mean_absolute_error: 23.4708\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 25.6824 - mean_absolute_error: 25.6824\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 21.6481 - mean_absolute_error: 21.6481\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 28.6932 - mean_absolute_error: 28.6932\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.0790 - mean_absolute_error: 21.0790\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 20.9302 - mean_absolute_error: 20.9302\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.2857 - mean_absolute_error: 21.2857\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 29.2331 - mean_absolute_error: 29.2331\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.8258 - mean_absolute_error: 27.8258\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.5786 - mean_absolute_error: 16.5786\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.1391 - mean_absolute_error: 24.1391\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.6260 - mean_absolute_error: 20.6260\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 18.2613 - mean_absolute_error: 18.2613\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.3322 - mean_absolute_error: 21.3322\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 40.3670 - mean_absolute_error: 40.3670\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 33.0898 - mean_absolute_error: 33.0898\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 38.6298 - mean_absolute_error: 38.6298\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 25.7028 - mean_absolute_error: 25.7028\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 26.3818 - mean_absolute_error: 26.3818\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 25.8014 - mean_absolute_error: 25.8014\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 28.4454 - mean_absolute_error: 28.4454\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 38.6022 - mean_absolute_error: 38.6022\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 35.8367 - mean_absolute_error: 35.8367\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 37.0153 - mean_absolute_error: 37.0153\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 38.4295 - mean_absolute_error: 38.4295\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 28.6129 - mean_absolute_error: 28.6129\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.9160 - mean_absolute_error: 17.9160\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.8156 - mean_absolute_error: 19.8156\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 19.9927 - mean_absolute_error: 19.9927\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.4323 - mean_absolute_error: 20.4323\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.5863 - mean_absolute_error: 14.5863\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.8769 - mean_absolute_error: 18.8769\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16.9756 - mean_absolute_error: 16.9756\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14.9815 - mean_absolute_error: 14.9815\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 12.3277 - mean_absolute_error: 12.3277\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.2686 - mean_absolute_error: 15.2686\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.2639 - mean_absolute_error: 27.2639\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 21.9683 - mean_absolute_error: 21.9683\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11.8271 - mean_absolute_error: 11.8271\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10.3465 - mean_absolute_error: 10.3465\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.5690 - mean_absolute_error: 10.5690\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11.7113 - mean_absolute_error: 11.7113\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 13.6815 - mean_absolute_error: 13.6815\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.4548 - mean_absolute_error: 27.4548\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 24.3952 - mean_absolute_error: 24.3952\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.1621 - mean_absolute_error: 20.1621\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 18.8211 - mean_absolute_error: 18.8211\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.0558 - mean_absolute_error: 20.0558\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 13.4371 - mean_absolute_error: 13.4371\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.0363 - mean_absolute_error: 14.0363\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.1093 - mean_absolute_error: 10.1093\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 12.1217 - mean_absolute_error: 12.1217\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.4790 - mean_absolute_error: 13.4790\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 24.1123 - mean_absolute_error: 24.1123\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 28.2230 - mean_absolute_error: 28.2230\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.0558 - mean_absolute_error: 24.0558\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.0396 - mean_absolute_error: 22.0396\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.8378 - mean_absolute_error: 19.8378\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.2580 - mean_absolute_error: 27.2580\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.5126 - mean_absolute_error: 17.5126\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.0554 - mean_absolute_error: 18.0554\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.7680 - mean_absolute_error: 19.7680\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.5242 - mean_absolute_error: 19.5242\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.5117 - mean_absolute_error: 23.5117\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 22.9801 - mean_absolute_error: 22.9801\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 14.5591 - mean_absolute_error: 14.5591\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.8526 - mean_absolute_error: 12.8526\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.8796 - mean_absolute_error: 15.8796\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.1888 - mean_absolute_error: 21.1888\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.0262 - mean_absolute_error: 27.0262\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.9138 - mean_absolute_error: 18.9138\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.6730 - mean_absolute_error: 21.6730\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 23.7416 - mean_absolute_error: 23.7416\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 22.0907 - mean_absolute_error: 22.0907\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.7812 - mean_absolute_error: 20.7812\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 28.4936 - mean_absolute_error: 28.4936\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 34.5648 - mean_absolute_error: 34.5648\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.9607 - mean_absolute_error: 23.9607\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.7475 - mean_absolute_error: 19.7475\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.4634 - mean_absolute_error: 10.4634\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 13.5430 - mean_absolute_error: 13.5430\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.4379 - mean_absolute_error: 18.4379\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.8686 - mean_absolute_error: 12.8686\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.5471 - mean_absolute_error: 10.5471\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.8301 - mean_absolute_error: 18.8301\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.3530 - mean_absolute_error: 21.3530\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.1396 - mean_absolute_error: 24.1396\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 24.5591 - mean_absolute_error: 24.5591\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.2720 - mean_absolute_error: 24.2720\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 25.5046 - mean_absolute_error: 25.5046\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 21.0227 - mean_absolute_error: 21.0227\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.1446 - mean_absolute_error: 21.1446\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.7874 - mean_absolute_error: 22.7874\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.2671 - mean_absolute_error: 21.2671\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 16.7500 - mean_absolute_error: 16.7500\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11.0535 - mean_absolute_error: 11.0535\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.7760 - mean_absolute_error: 10.7760\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 18.8219 - mean_absolute_error: 18.8219\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.1045 - mean_absolute_error: 10.1045\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.4283 - mean_absolute_error: 12.4283\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 17.6842 - mean_absolute_error: 17.6842\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 31.0048 - mean_absolute_error: 31.0048\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 32.6312 - mean_absolute_error: 32.6312\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 25.4972 - mean_absolute_error: 25.4972\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 25.9652 - mean_absolute_error: 25.9652\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 24.0369 - mean_absolute_error: 24.0369\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.2874 - mean_absolute_error: 18.2874\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 19.5037 - mean_absolute_error: 19.5037\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.1826 - mean_absolute_error: 19.1826\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.1189 - mean_absolute_error: 11.1189\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.6832 - mean_absolute_error: 14.6832\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.2123 - mean_absolute_error: 17.2123\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.0750 - mean_absolute_error: 17.0750\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.9004 - mean_absolute_error: 7.9004\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11.2335 - mean_absolute_error: 11.2335\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.2727 - mean_absolute_error: 12.2727\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.1862 - mean_absolute_error: 20.1862\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.0861 - mean_absolute_error: 19.0861\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.9640 - mean_absolute_error: 20.9640\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 12.1721 - mean_absolute_error: 12.1721\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.6779 - mean_absolute_error: 7.6779\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.7892 - mean_absolute_error: 11.7892\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.4612 - mean_absolute_error: 12.4612\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 12.9748 - mean_absolute_error: 12.9748\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.2575 - mean_absolute_error: 14.2575\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.6862 - mean_absolute_error: 9.6862\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 19.6711 - mean_absolute_error: 19.6711\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 29.9141 - mean_absolute_error: 29.9141\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.2548 - mean_absolute_error: 21.2548\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.0318 - mean_absolute_error: 18.0318\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.6478 - mean_absolute_error: 14.6478\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 19.2414 - mean_absolute_error: 19.2414\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 20.2284 - mean_absolute_error: 20.2284\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.9354 - mean_absolute_error: 16.9354\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.5909 - mean_absolute_error: 20.5909\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 20.8595 - mean_absolute_error: 20.8595\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.3336 - mean_absolute_error: 12.3336\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16.9865 - mean_absolute_error: 16.9865\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 18.8321 - mean_absolute_error: 18.8321\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 18.1810 - mean_absolute_error: 18.1810\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.0532 - mean_absolute_error: 12.0532\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.0976 - mean_absolute_error: 15.0976\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 22.2994 - mean_absolute_error: 22.2994\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.0010 - mean_absolute_error: 14.0010\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.5342 - mean_absolute_error: 11.5342\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10.4260 - mean_absolute_error: 10.4260\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.3025 - mean_absolute_error: 13.3025\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.1589 - mean_absolute_error: 20.1589\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.4776 - mean_absolute_error: 15.4776\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 15.7750 - mean_absolute_error: 15.7750\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.5860 - mean_absolute_error: 10.5860\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.1854 - mean_absolute_error: 9.1854\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.5638 - mean_absolute_error: 10.5638\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.5862 - mean_absolute_error: 18.5862\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 29.0416 - mean_absolute_error: 29.0416\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.4338 - mean_absolute_error: 21.4338\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 19.6932 - mean_absolute_error: 19.6932\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 18.2879 - mean_absolute_error: 18.2879\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.9183 - mean_absolute_error: 13.9183\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 25.2033 - mean_absolute_error: 25.2033\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.5336 - mean_absolute_error: 18.5336\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.6857 - mean_absolute_error: 12.6857\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 17.3311 - mean_absolute_error: 17.3311\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 26.8777 - mean_absolute_error: 26.8777\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.8545 - mean_absolute_error: 17.8545\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 26.3544 - mean_absolute_error: 26.3544\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 22.4743 - mean_absolute_error: 22.4743\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.9720 - mean_absolute_error: 21.9720\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 38.4119 - mean_absolute_error: 38.4119\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 33.9392 - mean_absolute_error: 33.9392\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 38.3106 - mean_absolute_error: 38.3106\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 27.5831 - mean_absolute_error: 27.5831\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 21.4993 - mean_absolute_error: 21.4993\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.2117 - mean_absolute_error: 18.2117\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.1858 - mean_absolute_error: 18.1858\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.6189 - mean_absolute_error: 21.6189\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.8803 - mean_absolute_error: 21.8803\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.1276 - mean_absolute_error: 22.1276\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.0992 - mean_absolute_error: 10.0992\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.3676 - mean_absolute_error: 13.3676\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.8832 - mean_absolute_error: 16.8832\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.4665 - mean_absolute_error: 20.4665\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 26.1319 - mean_absolute_error: 26.1319\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 26.1068 - mean_absolute_error: 26.1068\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.2689 - mean_absolute_error: 20.2689\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.4444 - mean_absolute_error: 12.4444\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.5881 - mean_absolute_error: 14.5881\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.5227 - mean_absolute_error: 12.5227\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.6607 - mean_absolute_error: 9.6607\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 13.3909 - mean_absolute_error: 13.3909\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.6985 - mean_absolute_error: 17.6985\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.6257 - mean_absolute_error: 17.6257\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11.6284 - mean_absolute_error: 11.6284\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.1110 - mean_absolute_error: 10.1110\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.8143 - mean_absolute_error: 13.8143\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.6923 - mean_absolute_error: 15.6923\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 13.8433 - mean_absolute_error: 13.8433\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.6628 - mean_absolute_error: 21.6628\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 21.7626 - mean_absolute_error: 21.7626\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.7160 - mean_absolute_error: 20.7160\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.0017 - mean_absolute_error: 17.0017\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.2818 - mean_absolute_error: 20.2818\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.6280 - mean_absolute_error: 14.6280\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.3070 - mean_absolute_error: 17.3070\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.8789 - mean_absolute_error: 15.8789\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 13.9808 - mean_absolute_error: 13.9808\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.7853 - mean_absolute_error: 9.7853\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11.6918 - mean_absolute_error: 11.6918\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.2912 - mean_absolute_error: 11.2912\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10.5850 - mean_absolute_error: 10.5850\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.4429 - mean_absolute_error: 11.4429\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.1874 - mean_absolute_error: 9.1874\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.6510 - mean_absolute_error: 12.6510\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.6776 - mean_absolute_error: 19.6776\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.7138 - mean_absolute_error: 19.7138\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.6510 - mean_absolute_error: 14.6510\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.5954 - mean_absolute_error: 17.5954\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.3820 - mean_absolute_error: 16.3820\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.0986 - mean_absolute_error: 20.0986\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.5750 - mean_absolute_error: 20.5750\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.4494 - mean_absolute_error: 15.4494\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.5798 - mean_absolute_error: 21.5798\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 27.9430 - mean_absolute_error: 27.9430\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.7189 - mean_absolute_error: 18.7189\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.3244 - mean_absolute_error: 18.3244\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.0673 - mean_absolute_error: 22.0673\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 31.9389 - mean_absolute_error: 31.9389\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 37.3981 - mean_absolute_error: 37.3981\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 34.3208 - mean_absolute_error: 34.3208\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.3077 - mean_absolute_error: 21.3077\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 24.6063 - mean_absolute_error: 24.6063\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 24.5180 - mean_absolute_error: 24.5180\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 26.8404 - mean_absolute_error: 26.8404\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 26.6917 - mean_absolute_error: 26.6917\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 17.1086 - mean_absolute_error: 17.1086\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 19.8490 - mean_absolute_error: 19.8490\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.5446 - mean_absolute_error: 20.5446\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15.4324 - mean_absolute_error: 15.4324\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.5610 - mean_absolute_error: 22.5610\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14.1667 - mean_absolute_error: 14.1667\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.6454 - mean_absolute_error: 14.6454\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 16.0171 - mean_absolute_error: 16.0171\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.8701 - mean_absolute_error: 15.8701\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.1652 - mean_absolute_error: 21.1652\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 24.4635 - mean_absolute_error: 24.4635\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 21.8261 - mean_absolute_error: 21.8261\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.1761 - mean_absolute_error: 17.1761\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 13.8491 - mean_absolute_error: 13.8491\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.8662 - mean_absolute_error: 12.8662\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.9584 - mean_absolute_error: 23.9584\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 24.7560 - mean_absolute_error: 24.7560\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.5714 - mean_absolute_error: 19.5714\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.9662 - mean_absolute_error: 18.9662\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 19.5507 - mean_absolute_error: 19.5507\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 17.1663 - mean_absolute_error: 17.1663\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 21.1136 - mean_absolute_error: 21.1136\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.7282 - mean_absolute_error: 15.7282\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17.5471 - mean_absolute_error: 17.5471\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.0008 - mean_absolute_error: 12.0008\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.2564 - mean_absolute_error: 11.2564\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.7396 - mean_absolute_error: 18.7396\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.9529 - mean_absolute_error: 18.9529\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 20.4161 - mean_absolute_error: 20.4161\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.3756 - mean_absolute_error: 12.3756\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 13.2701 - mean_absolute_error: 13.2701\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 20.1899 - mean_absolute_error: 20.1899\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.5672 - mean_absolute_error: 20.5672\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23.3134 - mean_absolute_error: 23.3134\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 25.6298 - mean_absolute_error: 25.6298\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.6481 - mean_absolute_error: 8.6481\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.2257 - mean_absolute_error: 11.2257\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12.0057 - mean_absolute_error: 12.0057\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.9637 - mean_absolute_error: 8.9637\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.1492 - mean_absolute_error: 14.1492\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.6976 - mean_absolute_error: 18.6976\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.8705 - mean_absolute_error: 20.8705\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.7524 - mean_absolute_error: 14.7524\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.4832 - mean_absolute_error: 10.4832\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.2509 - mean_absolute_error: 12.2509\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.2849 - mean_absolute_error: 17.2849\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 13.6233 - mean_absolute_error: 13.6233\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11.7104 - mean_absolute_error: 11.7104\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.9166 - mean_absolute_error: 11.9166\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18.9978 - mean_absolute_error: 18.9978\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 20.5942 - mean_absolute_error: 20.5942\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 19.8578 - mean_absolute_error: 19.8578\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12.1494 - mean_absolute_error: 12.1494\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.8808 - mean_absolute_error: 10.8808\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 12.0961 - mean_absolute_error: 12.0961\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 27.7194 - mean_absolute_error: 27.7194\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 38.9485 - mean_absolute_error: 38.9485\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 32.3413 - mean_absolute_error: 32.3413\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 28.8587 - mean_absolute_error: 28.8587\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 23.3792 - mean_absolute_error: 23.3792\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 26.3931 - mean_absolute_error: 26.3931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDjXWRuH5_Lh",
        "outputId": "8de9466c-4a43-4366-e2d6-4494b0cc166f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9969848925607093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nOUkWgQE1TH",
        "outputId": "9b245d27-9515-4e9a-8d7f-87ba606808dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "test_loss = []\n",
        "test_loss.append(mean_squared_error(y_test, y_pred))\n",
        "print(\"Test loss: {}\".format(test_loss))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: [140.653175148908]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usGbuJSy9fAi"
      },
      "source": [
        "# Now with our base model, we are getting close to 1, we can do the hyper   parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-C-gDBb-FEF"
      },
      "source": [
        "def tuning_model(unit = 256,kernel_initializer='normal'):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, kernel_initializer='normal',input_dim = 5, activation='relu'))\n",
        "\n",
        "  # Creating 3 hidden layers\n",
        "  model.add(Dense(units=unit, kernel_initializer=kernel_initializer,activation='relu'))\n",
        "  model.add(Dense(units=unit, kernel_initializer=kernel_initializer,activation='relu'))\n",
        "  model.add(Dense(units=unit, kernel_initializer=kernel_initializer,activation='relu'))\n",
        "\n",
        "  # The Output Layer :\n",
        "  model.add(Dense(1, kernel_initializer=kernel_initializer,activation='linear'))\n",
        "  model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypVINOCv5-NK"
      },
      "source": [
        "# Need a Keras wrapper over the base_model \n",
        "classifier = KerasRegressor(build_fn=tuning_model)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdpAUXeTjRzh"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# parameters ={'nb_epoch':[500,1000,2000],\n",
        "#             'kernel_initializer':['random_uniform', 'normal'],\n",
        "#             'unit':[128,256,512],\n",
        "#              'learn_rate':[0.01, 0.1, 0.2],\n",
        "#              'batch_size' : [128,256,512]}\n",
        "parameters ={'nb_epoch':[500,1000,2000],\n",
        "            'kernel_initializer':['random_uniform', 'normal'],\n",
        "            'unit':[128,256,512],\n",
        "             'batch_size' : [128,256,512]}\n",
        "gridSearch = GridSearchCV(classifier,param_grid=parameters,\n",
        "                          cv=4,\n",
        "                         n_jobs=-1,\n",
        "                         return_train_score=True,\n",
        "                          scoring='r2',\n",
        "                          verbose = 2\n",
        "                          )"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vwpQCP2jWKh",
        "outputId": "667c3526-dd83-45c5-fe5c-446bf5008fe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "hist = gridSearch.fit(X_train, y_train)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   26.4s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_105 (Dense)            (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 592,641\n",
            "Trainable params: 592,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 5558.4677 - mean_absolute_error: 5558.4676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXzlsoLZ1nGT",
        "outputId": "2583777d-9ddf-43f4-fbaf-1d86fdac8a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Grid Search Best score',hist.best_score_)\n",
        "print('Grid Search Best Parameters', hist.best_params_)\n",
        "print('Execution time',hist.refit_time_)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grid Search Best score -630.0527045677327\n",
            "Grid Search Best Parameters {'batch_size': 128, 'kernel_initializer': 'normal', 'nb_epoch': 2000, 'unit': 512}\n",
            "Execution time 1.2632217407226562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P7f-kyeRYyy"
      },
      "source": [
        "model1 = KerasRegressor(build_fn = base_model,verbose = 0,epochs = 2000,kernel_initializer='random_uniform',unit = 512, batch_size = 128)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOj3UgKyXw3f",
        "outputId": "601e22be-373b-4288-e3f8-40f6d4e444fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model1.fit(X_train,y_train)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_115 (Dense)            (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 592,641\n",
            "Trainable params: 592,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f616130e6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0yFYCkYCne5",
        "outputId": "994aa04d-b338-43ef-db87-fda9a883be25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred1 = model1.predict(X_test)\n",
        "print(y_test.head())\n",
        "print(y_pred[:5])"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           y\n",
            "32    5655.7\n",
            "1495  5562.2\n",
            "262   5588.5\n",
            "1386  5434.2\n",
            "469   5514.3\n",
            "[[5642.36083513]\n",
            " [5552.89922265]\n",
            " [5575.7465957 ]\n",
            " [5418.53345701]\n",
            " [5499.01500222]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk_juen8YYgU",
        "outputId": "b8765fed-e2d8-4016-98d0-197927112c15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "test_loss = []\n",
        "test_loss.append(mean_squared_error(y_test, y_pred1))\n",
        "print(\"Test loss: {}\".format(test_loss))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: [965.1059368591498]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gtM_XqfgJO-",
        "outputId": "6ac19372-33bd-490d-f5b6-26898b203fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(y_test,y_pred1))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9793115364310337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flrx-IIXdc5z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}